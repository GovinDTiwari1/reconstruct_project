üé• Jumbled Video Frame Reconstruction Project
üß© Project Overview

This project reconstructs a jumbled or scrambled video by analyzing individual frames, determining the correct order, and rebuilding the video in its original sequence.

‚öôÔ∏è 1. Installation Instructions
üß∞ Requirements

Install these before running the project:

Tools

FFmpeg ‚Äì for splitting and merging videos
üëâ Download: https://www.gyan.dev/ffmpeg/builds/

Add the bin folder to your System PATH.
Test:

ffmpeg -version


GCC (MinGW) ‚Äì for compiling the C reconstruction program
üëâ Download: https://sourceforge.net/projects/mingw/

Test:

gcc --version


Python 3.10+ ‚Äì for post-processing and optional reordering fix
Install dependencies:

pip install pillow numpy opencv-python

‚ñ∂Ô∏è 2. How to Run the Code
Step 1 ‚Äì Extract Frames

Extract frames from the input jumbled video:

ffmpeg -i jumbled_video.mp4 -start_number 0 -q:v 2 frames/frame%03d.jpg


‚úÖ This saves all frames inside the frames/ folder as frame000.jpg, frame001.jpg, etc.

Step 2 ‚Äì Compile the Reconstruction Code

Make sure reconstruct.c and stb_image.h are in the same folder.
Then compile:

gcc -O2 -lm -o reconstruct reconstruct.c

Step 3 ‚Äì Generate the Frame Order

Run:

.\reconstruct frames 300 list.txt


üëâ This will analyze the 300 frames and generate list.txt containing the reordered frame list.

Step 4 ‚Äì Fix Frame Order(auto_reorder.py)

RUN auto_reorder.py

If the video looks reversed, run this Python script (reverse_list.py):

RUN reverse_list.py


Run:

python reverse_list.py

Step 5 ‚Äì Rebuild the Video

Combine the ordered frames into a new video:

ffmpeg -f concat -safe 0 -i list_correct.txt -vf "scale=trunc(iw/2)*2:trunc(ih/2)*2" -c:v libx264 -pix_fmt yuv420p final_fixed.mp4


‚úÖ Output:

frames/ ‚Üí Extracted frames

list.txt ‚Üí Raw frame order

list_correct.txt ‚Üí Fixed order

final_fixed.mp4 ‚Üí Final reconstructed video

üß† 3. Algorithm Explanation
Technique Used:

Similarity-Based Frame Sequencing

Each frame is compared with others using pixel difference and structural similarity (SSIM).

The frame with the most similar next frame is linked, reconstructing the original sequence.

Approach:

Convert each frame to grayscale.

Measure visual similarity between consecutive frames using Mean Squared Error (MSE) or SSIM.

Start from the first frame and iteratively pick the most similar next frame.

Save the detected order in a list.txt file.

Optionally use a small heuristic to reverse mid-portion if half the video plays backward.

Why This Method:

Simple, effective for gradual motion videos (no need for heavy AI models).

Avoids high computational cost of CNNs or optical flow.

Easy to implement in C for speed.

Design Considerations:

Accuracy: Uses pixel-level similarity for precise frame matching.

Time Complexity: O(n¬≤) comparisons, acceptable for up to ~500 frames.

Parallelism: Can be optimized using multi-threading for faster processing.

‚è±Ô∏è 4. Execution Time Log
| Step                        | Description                                  | Time Taken      |
| --------------------------- | -------------------------------------------- | --------------- |
| Frame Extraction            | Using FFmpeg (`jumbled_video.mp4 ‚Üí frames/`) | ~2 seconds      |
| Frame Analysis & Reordering | C code (`reconstruct.c`)                     | ~6 seconds      |
| Final Video Reconstruction  | FFmpeg combine                               | ~2 seconds      |
| **Total**                   |                                              | **~10 seconds** |
